{"meta":{"title":"Hexo","subtitle":"","description":true,"author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"乐观锁和悲观锁","slug":"乐观锁和悲观锁","date":"2019-09-12T13:50:09.000Z","updated":"2020-09-05T15:57:30.658Z","comments":true,"path":"2019/09/12/乐观锁和悲观锁/","link":"","permalink":"http://example.com/2019/09/12/%E4%B9%90%E8%A7%82%E9%94%81%E5%92%8C%E6%82%B2%E8%A7%82%E9%94%81/","excerpt":"何谓悲观锁与乐观锁 乐观锁对应于生活中乐观的人总是想着事情往好的方向发展，悲观锁对应于生活中悲观的人总是想着事情往坏的方向发展。这两种人各有优缺点，不能不以场景而定说一种人好于另外一种人","text":"何谓悲观锁与乐观锁 乐观锁对应于生活中乐观的人总是想着事情往好的方向发展，悲观锁对应于生活中悲观的人总是想着事情往坏的方向发展。这两种人各有优缺点，不能不以场景而定说一种人好于另外一种人 乐观锁 总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的 悲观锁 总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现 两种锁的使用场景 从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适 cas在多写情况下自旋：非公平锁和公平锁（队列维护） CAS算法 即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。 CAS（总读取主内存的值） CAS与synchronized的使用情景 简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多）","categories":[],"tags":[]},{"title":"高并发的理解和使用场景","slug":"高并发的理解和使用场景","date":"2019-09-12T12:52:10.000Z","updated":"2020-09-05T15:49:17.971Z","comments":true,"path":"2019/09/12/高并发的理解和使用场景/","link":"","permalink":"http://example.com/2019/09/12/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%9A%84%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/","excerpt":"高并发的理解 就是短时间内遇到大量操作请求，导致站点服务器/db服务器资源被占满甚至严重时直接导致宕","text":"高并发的理解 就是短时间内遇到大量操作请求，导致站点服务器/db服务器资源被占满甚至严重时直接导致宕 衡量一个系统的好坏，除了业务外，还有就是系统的吞吐量（单位时间内处理的请求数）—–QPS（每秒钟能处理的请求数）和响应时间 高并发和多线程的关系 多线程的理解 多线程是java的特性，因为现在cpu都是多核多线程的，可以同时执行几个任务，为了提高jvm的执行效率，java提供了这种多线程的机制，以增强数据处理效率 多线程对应的是cpu，高并发对应的是访问请求，可以用单线程处理所有访问请求，也可以用多线程同时处理访问请求 在过去单CPU时代，单任务在一个时间点只能执行单一程序。之后发展到多任务阶段，计算机能在同一时间点并行执行多任务或多进程。虽然并不是真正意义上的“同一时间点”，而是多个任务或进程共享一个CPU，并交由操作系统来完成多任务间对CPU的运行切换，以使得每个任务都有机会获得一定的时间片运行 再后来发展到多线程技术，使得在一个程序内部能拥有多个线程并行执行。一个线程的执行可以被认为是一个CPU在执行该程序。当一个程序运行在多线程下，就好像有多个CPU在同时执行该程序 并发编程的几个要素 原子性原子，即一个不可再被分割的颗粒。在Java中原子性指的是一个或多个操作要么全部执行成功要么全部执行失败 有序性程序执行的顺序按照代码的先后顺序执行。（处理器可能会对指令进行重排序） 可见性当多个线程访问同一个变量时，如果其中一个线程对其作了修改，其他线程能立即获取到最新的值 高并发的场景 一般像火车票抢票，秒杀 系统，双11或者京东618活动等这种太明显不过了，这种还是正常的业务范围，蛮好理解的，还有一种就是恶意的攻击，导致系统的某个功能近乎瘫痪，比如验证码的请求等 高并发难点 并发时最怕的就是对共享变量的同时访问导致脏数据的产生，所以一般会加锁：对象锁（例如：syncrinized等关键字）和 分布式锁（数据库锁，redis，zookeeper） 对象锁顾名思义就是锁住当前对象–只能用在单服务器上，对于分布式系统或者单系统分布式部署时对共享资源的访问就必须使用分布式锁了，此时对象锁没法用了 像秒杀系统可以使用缓存让还有数量时都可以看到，而在开抢后得看个人运气了（网络等原因），此时使用乐观锁（共享锁）就搞定了嘛 像银行的消费后更新银行卡余额，使用悲观锁（排斥锁）就可以","categories":[],"tags":[]},{"title":"Redis内存淘汰策略","slug":"Redis内存淘汰策略","date":"2019-08-05T14:56:08.000Z","updated":"2020-09-05T15:57:19.362Z","comments":true,"path":"2019/08/05/Redis内存淘汰策略/","link":"","permalink":"http://example.com/2019/08/05/Redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/","excerpt":"为什么需要内存淘汰策略 长期将Redis作为缓存使用，难免会遇到内存空间存储瓶颈，当Redis内存超出物理内存限制时，内存数据就会与磁盘产生频繁交换，使Redis性能急剧下降。","text":"为什么需要内存淘汰策略 长期将Redis作为缓存使用，难免会遇到内存空间存储瓶颈，当Redis内存超出物理内存限制时，内存数据就会与磁盘产生频繁交换，使Redis性能急剧下降。 使用配置(针对redis.conf) maxmemory 100mb (最大内存,0表示不限制) maxmemory-policy (选择策略) 内存淘汰策略工作流程 客户端会发起需要更多内存的申请 Redis检查内存使用情况，如果实际使用内存已经超出maxmemory，Redis就会根据用户配置的淘汰策略选出无用的key 确认选中数据没有问题，成功执行淘汰任务 淘汰策略 volatile-lru 从设置过期时间的数据集中挑选出最近最少使用的数据淘汰。没有设置过期时间的key不会被淘汰，这样就可以在增加内存空间的同时保证需要持久化的数据不会丢失 volatile-ttl 只从设置失效（expire set）的key中，选出存活时间（TTL）最短的key进行删除，用以保存新数据 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰。当内存达到限制无法写入非过期时间的数据集时，可以通过该淘汰策略在主键空间中随机移除某个key allkeys-lru 从数据集中挑选最近最少使用的数据淘汰，该策略要淘汰的key面向的是全体key集合，而非过期的key集合 allkeys-random 从数据集中选择任意数据淘汰 no-enviction 禁止驱逐数据，也就是当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用no-enviction策略可以保证数据不被丢失，这也是系统默认的一种淘汰策略 LRU淘汰机制 服务器配置中保存了 lru 计数器 server.lrulock，会定时（redis 定时程序 serverCorn()）更新，server.lrulock 的值是根据 server.unixtime 计算出来进行排序的，然后选择最近使用时间最久的数据进行删除。另外，从 struct redisObject 中可以发现，每一个 redis 对象都会设置相应的 lru。每一次访问数据，会更新对应redisObject.lru 在Redis中，LRU算法是一个近似算法，默认情况下，Redis会随机挑选5个键，并从中选择一个最久未使用的key进行淘汰。在配置文件中，按maxmemory-samples选项进行配置，选项配置越大，消耗时间就越长，但结构也就越精准(近似非绝对) TTL淘汰 Redis 数据集数据结构中保存了键值对过期时间的表，即 redisDb.expires。与 LRU 数据淘汰机制类似，TTL 数据淘汰机制中会先从过期时间的表中随机挑选几个键值对，取出其中 ttl 最大的键值对淘汰。同样，TTL淘汰策略并不是面向所有过期时间的表中最快过期的键值对，而只是随机挑选的几个键值对(近似非绝对) 随机淘汰 在随机淘汰的场景下获取待删除的键值对，随机找hash桶再次hash指定位置的dictEntry(指针指向下一个即可:链表)","categories":[],"tags":[]}],"categories":[],"tags":[]}